{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "'''\n",
    "A linear regression learning algorithm example using TensorFlow library.\n",
    "\n",
    "Author: Aymeric Damien\n",
    "Project: https://github.com/aymericdamien/TensorFlow-Examples/\n",
    "'''\n",
    "\n",
    "from __future__ import print_function\n",
    "\n",
    "import glob\n",
    "import pickle\n",
    "\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "num samples 6402\n"
     ]
    }
   ],
   "source": [
    "# Parameters\n",
    "learning_rate = 1e-4\n",
    "training_epochs = 20000\n",
    "display_step = 50\n",
    "\n",
    "files = glob.glob('/home/sameh/distance_data/*.p')\n",
    "data = dict()\n",
    "for f in files:\n",
    "    data.update(pickle.load(open(f, 'rb')))\n",
    "\n",
    "_X = []\n",
    "_Y = []\n",
    "\n",
    "for time, _data in data.items():\n",
    "   _X.append(_data['signal_level'])\n",
    "   _Y.append(_data['distance_cm']) \n",
    "\n",
    "\n",
    "_X_train = _X[:int(.7*len(_X))]\n",
    "_Y_train = _Y[:int(.7*len(_X))]\n",
    "\n",
    "_X_test = _X[int(.7*len(_X)):]\n",
    "_Y_test = _Y[int(.7*len(_X)):]\n",
    "\n",
    "\n",
    "test_X = np.array(_X_test)\n",
    "test_Y = np.array(_Y_test)\n",
    "    \n",
    "# Training Data\n",
    "train_X = np.array(_X_train)\n",
    "train_Y = np.array(_Y_train)\n",
    "\n",
    "n_samples = train_X.shape[0]\n",
    "\n",
    "print(\"num samples {}\".format(n_samples))\n",
    "\n",
    "# %% tf.placeholders for the input and output of the network. Placeholders are\n",
    "# variables which we need to fill in when we are ready to compute the graph.\n",
    "X = tf.placeholder(tf.float32)\n",
    "Y = tf.placeholder(tf.float32)\n",
    "\n",
    "# %% Instead of a single factor and a bias, we'll create a polynomial function\n",
    "# of different polynomial degrees.  We will then learn the influence that each\n",
    "# degree of the input (X^0, X^1, X^2, ...) has on the final output (Y).\n",
    "Y_pred = tf.Variable(tf.random_normal([1]), name='bias')\n",
    "for pow_i in range(1, 3):\n",
    "    W = tf.Variable(tf.random_normal([1]), name='weight_%d' % pow_i)\n",
    "    Y_pred = tf.add(tf.multiply(tf.pow(X, pow_i), W), Y_pred)\n",
    "\n",
    "# Mean squared error\n",
    "# %% Loss function will measure the distance between our observations\n",
    "# and predictions and average over them.\n",
    "cost = tf.reduce_sum(tf.pow(Y_pred - Y, 2)) / (n_samples - 1)\n",
    "\n",
    "# cost = tf.reduce_sum(tf.pow(Y_pred - Y, 2))/(2*n_samples)\n",
    "# Gradient descent\n",
    "#  Note, minimize() knows to modify W and b because Variable objects are trainable=True by default\n",
    "optimizer = tf.train.AdamOptimizer(learning_rate).minimize(cost)\n",
    "\n",
    "# Initializing the variables\n",
    "# init = tf.global_variables_initializer()\n",
    "\n",
    "#Create a saver object which will save all the variables\n",
    "saver = tf.train.Saver()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "316068.0\n",
      "0.835683\n",
      "0.780441\n",
      "0.729013\n",
      "0.681555\n",
      "0.638102\n",
      "0.598497\n",
      "0.562351\n",
      "0.53019\n",
      "0.501189\n"
     ]
    }
   ],
   "source": [
    "sess = tf.Session()\n",
    "    \n",
    "sess.run(tf.global_variables_initializer())\n",
    "\n",
    "# Fit all training data\n",
    "prev_training_cost = 0.0\n",
    "for epoch_i in range(training_epochs):\n",
    "    for (x, y) in zip(train_X, train_Y):\n",
    "        sess.run(optimizer, feed_dict={X: x, Y: y})\n",
    "    training_cost = sess.run(\n",
    "        cost, feed_dict={X: train_X, Y: train_Y})\n",
    "        \n",
    "    if epoch_i % 500 == 0:\n",
    "        print(training_cost)\n",
    "\n",
    "saver.save(sess, '20k-poly-model-1e-4/20k-poly-model-1e-4')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.scatter(test_X, Y_pred.eval(feed_dict={X: test_X}, session=sess), color='r')\n",
    "plt.scatter(test_X, test_Y, color='g')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "x = test_X[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y_pred.eval(feed_dict={X:x}, session=sess)[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
